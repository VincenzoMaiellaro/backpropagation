{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86681258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2165880",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Value:\n",
    "  def __init__(self, data, _children = (), _op = ''):\n",
    "    self.data = data #value\n",
    "    self._prev = set(_children) #who \"creates\" the value\n",
    "    self._op = _op #operation that \"created the value\"\n",
    "    self.grad = 0\n",
    "    '''\n",
    "    function that will apply the chain rule for each node\n",
    "    that is, distribute the gradient values according to the operation\n",
    "    performed, so it is the function that does backpropagation of the gradient.\n",
    "    This function by default does nothing because there are leaf nodes\n",
    "    like the bias\n",
    "    '''\n",
    "    self._backward =  lambda : None\n",
    "\n",
    "  def __repr__(self):\n",
    "    return f\"Value(data = {self.data})\"\n",
    "  '''\n",
    "  when using addition the derivative is 1 and this passes the gradient\n",
    "  from the created node back equally to both nodes\n",
    "  '''\n",
    "  def __add__(self, other):\n",
    "    #if other is of type Value it's fine, otherwise we create it as Value\n",
    "    other = other if isinstance(other, Value) else Value(other)\n",
    "    out = Value(self.data + other.data, (self,other), '+')\n",
    "    def _backward():\n",
    "      '''\n",
    "      use += in operations because you must not overwrite the gradient,\n",
    "      but accumulate it (there is a bug when using the same variable for example\n",
    "      b = a + a, the gradient of a is wrong, because it would overwrite it if\n",
    "      we used = instead of +=)\n",
    "      '''\n",
    "      self.grad += 1.0 * out.grad\n",
    "      other.grad += 1.0 * out.grad\n",
    "    out._backward = _backward\n",
    "    return out\n",
    "\n",
    "  def __radd__(self, other):  # fallback for when you have other + self\n",
    "    return self + other\n",
    "\n",
    "  def __rmul__(self, other): #fallback for when you have other * self\n",
    "    return self * other\n",
    "\n",
    "  '''\n",
    "  when using multiplication, the gradient value is calculated as\n",
    "  the created gradient value multiplied by the value of the other node\n",
    "  '''\n",
    "  def __mul__(self, other):\n",
    "    #if other is of type Value it's fine, otherwise we create it as Value\n",
    "    other = other if isinstance(other, Value) else Value(other)\n",
    "    out = Value(self.data * other.data, (self,other), '*')\n",
    "    def _backward():\n",
    "      self.grad += out.grad * other.data\n",
    "      other.grad += out.grad * self.data\n",
    "    out._backward = _backward\n",
    "    return out\n",
    "  '''\n",
    "  need to implement another tanh because so far we have only implemented\n",
    "  sum and multiplication, while tanh also uses exponential in fact:\n",
    "  tanh(x) = (e^(2x) - 1) / (e^(2x) + 1) and obviously also implement\n",
    "  division.\n",
    "  Whether the implemented operation is simple or extremely complex, the important thing\n",
    "  is that we know how to find the local derivative of these\n",
    "  operations to know how the input affects the output\n",
    "  '''\n",
    "  def tanh(self):\n",
    "    x = self.data\n",
    "    t = (math.exp(2 * x) - 1) / (math.exp(2 * x) + 1)\n",
    "    out = Value(t, (self, ), 'tanh')\n",
    "    def _backward():\n",
    "      '''\n",
    "      to propagate backward through tanh we need to know the local derivative\n",
    "      of tanh, derivative of tanh = 1 - tanh(x)^2\n",
    "      '''\n",
    "      self.grad += (1 - t**2) * out.grad\n",
    "    out._backward = _backward\n",
    "    return out\n",
    "\n",
    "  '''\n",
    "  functions that decompose tanh into smaller pieces\n",
    "  '''\n",
    "  def __neg__(self):  #-self\n",
    "    return self * -1\n",
    "\n",
    "  def __sub__(self, other): #subtraction self - other\n",
    "    return self + (-other)\n",
    "\n",
    "  def exp(self): #exponential function\n",
    "    x = self.data\n",
    "    out = Value(math.exp(x), (self, ), 'exp')\n",
    "    def _backward():\n",
    "      self.grad += out.data * out.grad #derivative of exp\n",
    "    out._backward = _backward\n",
    "    return out\n",
    "\n",
    "  '''\n",
    "  division can be decomposed as follows:\n",
    "  a / b -> a * (1/b) -> a * (b**-1)\n",
    "  '''\n",
    "  def __truediv__(self, other): #self/other\n",
    "    return self * other**-1\n",
    "\n",
    "  def __pow__(self, other): #power function\n",
    "    assert isinstance(other, (int, float)) #supports only int/float power\n",
    "    out = Value(self.data**other, (self,), f'**{other}')\n",
    "    def _backward():\n",
    "      self.grad +=  other * (self.data ** (other - 1)) * out.grad #derivative of power\n",
    "    out._backward = _backward\n",
    "    return out\n",
    "\n",
    "\n",
    "  def backward(self):\n",
    "    #for topological ordering\n",
    "    topo = []\n",
    "    visited = set()\n",
    "    def build_topo(v):\n",
    "        if v not in visited:\n",
    "            visited.add(v)\n",
    "            for child in v._prev:\n",
    "                build_topo(child)\n",
    "            topo.append(v)\n",
    "    build_topo(self)\n",
    "    self.grad = 1.0 #the gradient of the final result is 1.0 (base case)\n",
    "    for node in reversed(topo):\n",
    "      node._backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3560e8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "  def __init__(self, nin): #nin = number of inputs for the neuron\n",
    "    self.w = [Value(random.uniform(-1, 1)) for _ in range(nin)] #weights of the neuron for each input\n",
    "    self.b = Value(random.uniform(-1, 1)) #bias of the neuron\n",
    "\n",
    "  def __call__(self, x):  #output of the neuron\n",
    "    # w * x + b\n",
    "    '''\n",
    "    #zip takes two iterators, and creates a new iterator that iterates over pairs from the input iterators\n",
    "    '''\n",
    "    act = sum((wi*xi for wi, xi in zip(self.w, x)), self.b)\n",
    "    out = act.tanh() #activation function\n",
    "    return out\n",
    "\n",
    "  def parameters(self): #returns the parameters\n",
    "    return self.w + [self.b]\n",
    "\n",
    "class Layer:\n",
    "  def __init__(self, nin, nout):\n",
    "    #a layer is a list of neurons (equal to the number of n output (nout))\n",
    "    #this indicates the number of neurons in a single layer\n",
    "    self.neurons = [Neuron(nin) for _ in range(nout)]\n",
    "\n",
    "  def __call__(self, x):\n",
    "    outs = [n(x) for n in self.neurons]\n",
    "    return outs[0] if len(outs) == 1 else outs\n",
    "\n",
    "  def parameters(self):\n",
    "    '''\n",
    "    params = []\n",
    "    for neuron in self.neurons:\n",
    "      ps = neuron.parameters()\n",
    "      params.extend(ps)\n",
    "    return params\n",
    "\n",
    "    this code can be simplified as follows:\n",
    "    '''\n",
    "    return [p for neuron in self.neurons for p in neuron.parameters()]\n",
    "\n",
    "\n",
    "\n",
    "class MLP:\n",
    "  def __init__(self, nin, nouts): #nouts indicates the size of each layer of neurons\n",
    "    sz = [nin] + nouts\n",
    "    self.layers = [Layer(sz[i], sz[i+1]) for i in range(len(nouts))]\n",
    "\n",
    "  def __call__(self, x):\n",
    "    for layer in self.layers:\n",
    "      x = layer(x)\n",
    "    return x\n",
    "\n",
    "  def parameters(self):\n",
    "    return [p for layer in self.layers for p in layer.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82885b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLP definition\n",
    "x = [2.0, 3.0, -1.0] #example input\n",
    "'''\n",
    "[4, 4, 1] = list that defines the layers:\n",
    " - First hidden layer: 4 neurons (receives the 3 inputs)\n",
    " - Second hidden layer: 4 neurons (receives output from the first layer)\n",
    " - Output layer: 1 neuron (receives output from the second layer)\n",
    "'''\n",
    "n = MLP(3, [4, 4, 1])\n",
    "n(x) #passes the input through the network and calculates the final output (network prediction for the initial input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9b4d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data definition (another example input)\n",
    "xs = [ #inputs\n",
    "    [2.0, 3.0, -1.0],\n",
    "    [3.0, -1.0, 0.5],\n",
    "    [0.5, 1.0, 1.0],\n",
    "    [1.0, 1.0, -1.0],\n",
    "]\n",
    "ys = [1.0, -1.0, -1.0, 1.0] # desired targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f229c806",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "the loss tells us how our network is performing,\n",
    "it is the sum of the squared difference between the desired predictions and the actual predictions of the network\n",
    "obviously we want to minimize this value\n",
    "'''\n",
    "for k in range(10):\n",
    "\n",
    "  #forward pass\n",
    "  ypred = [n(x) for x in xs]\n",
    "  loss = sum((yout - ygt)**2 for ygt, yout in zip(ys, ypred))\n",
    "\n",
    "  #backward pass\n",
    "  for p in n.parameters():\n",
    "    #we need to reset the gradients to zero as in the initial constructor, so all go to 0 for each iteration\n",
    "    #and the backward then takes the loss and passes the gradient to all\n",
    "    p.grad = 0.0\n",
    "  loss.backward()\n",
    "\n",
    "  '''\n",
    "  gradient descent: think of the gradient as the vector that points in the direction of increase of the loss function.\n",
    "  We want to decrease the loss function, so we need to move in the opposite direction of the gradient. This must be done in many small\n",
    "  steps (learning rate) and if we take too large a step we might skip the optimum,\n",
    "  in this case training becomes unstable and the loss increases.\n",
    "  '''\n",
    "  #update (gradient descent)\n",
    "  for p in n.parameters():\n",
    "    p.data += -0.05 * p.grad # -0.05 is the learning rate\n",
    "\n",
    "  print(k, loss.data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_analyzer_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
